
count_file: "mock_data_lc/lc_mirna_counts.csv"
metadata_file: "mock_data_lc/lc_dataset.csv"
# count_holdout_test_set: None
# metadata_holdout_test_set: None
 
preprocessing:
  train_test_split_params:
    test_size: 0.2
    random_state: 42

  threshold_filter_params:
      min_count: 10
      min_samples: 3

  normalization_methods:
    tmm:
      use_method: False
    cpm:
      use_method: False
    vst:
      use_method: True
    deseq2:
      use_method: False

  scaling_methods_metadata: # Use only on metadata
    standard_scale:
      use_method: False
    min_max_scale:
      use_method: False
    max_abs_scale:
      use_method: False

  scaling_methods_count: # Optional scaling on count data
    shrinkage_scaling: # Not implemented
      use_method: False 

  pca:
      use_method: True
      n_components: 2
      color_by: "condition"

  pre_filter_methods:
    variance_filter:
      use_method: False
      threshold: 0.5
    expr_percentile_filter:
      use_method: False
      threshold_percentile: 0.8
    correlation_filter:
      use_method: True
      correlation_method: "spearman" # or "pearson", "kendall"
      threshold: 0.9

feature_selection:

  random_forest:
    param_grid_gridsearchCV: 
      n_estimators: [50, 100, 200, 300]
      max_depth: [None, 10, 20, 30]
      max_features: [0.1, 1.0]
      min_samples_split: [2, 5, 10]
    space_params_hyperopt:
      criterion:
        parameter_type: choice
        values: ["entropy", "gini"]
      max_depth:
        parameter_type: quniform
        values: [10, 1200, 10]
      max_features:
        parameter_type: choice
        values: ["sqrt", "log2", "None"]
      min_samples_leaf: 
        parameter_type: uniform
        values: [0, 0.5]
      min_samples_split: 
        parameter_type: uniform
        values: [0, 1]
      n_estimators:
        parameter_type: choice
        values: [10, 50, 300, 750, 1200, 1300, 1500]


    